{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51MqS8SeIraS",
        "outputId": "687518ac-5196-4687-c7f1-18aa32c267fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting mcschematic\n",
            "  Downloading mcschematic-11.4.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting nbtlib>=2.0.4 (from mcschematic)\n",
            "  Downloading nbtlib-2.0.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting immutable-views (from mcschematic)\n",
            "  Downloading immutable_views-0.6.1-py2.py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading mcschematic-11.4.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbtlib-2.0.4-py3-none-any.whl (28 kB)\n",
            "Downloading immutable_views-0.6.1-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: nbtlib, immutable-views, mcschematic\n",
            "Successfully installed immutable-views-0.6.1 mcschematic-11.4.3 nbtlib-2.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow numpy matplotlib mcschematic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mcschematic\n",
        "import math"
      ],
      "metadata": {
        "id": "n22jSkLPkONj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "dYQLPkrSwgln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. LOAD DATA\n",
        "def load_data():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = np.where(x_train / 255.0 >= 0.5, 1, 0)\n",
        "    x_test = np.where(x_test / 255.0 >= 0.5, 1, 0)\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "\n",
        "# 2. TRAINING\n",
        "def train_pro_model(x_train, y_train, x_test, y_test):\n",
        "    l1_strength = 0.0005\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(\n",
        "            10,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=tf.keras.regularizers.l1(l1_strength),\n",
        "            bias_regularizer=tf.keras.regularizers.l1(l1_strength),\n",
        "        ),\n",
        "        tf.keras.layers.Dense(\n",
        "            10,\n",
        "            activation='softmax',\n",
        "            kernel_regularizer=tf.keras.regularizers.l1(l1_strength),\n",
        "            bias_regularizer=tf.keras.regularizers.l1(l1_strength),\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    print(f\"Training PRO model (L1: {l1_strength})...\")\n",
        "    model.fit(x_train, y_train, epochs=40, verbose=0)\n",
        "    return model\n",
        "\n",
        "\n",
        "# 3. SIMULATION (TARGET 127)\n",
        "def simulate_optimized_accuracy(model, x_test, y_test):\n",
        "    print(\"\\n=== OPTIMAL SIMULATION (Hidden ±7 | Output ±127) ===\")\n",
        "\n",
        "    h_layer = model.layers[1]\n",
        "    w_h, b_h = h_layer.get_weights()\n",
        "    o_layer = model.layers[2]\n",
        "    w_o, b_o = o_layer.get_weights()\n",
        "\n",
        "    # Hidden layer scaling (target ±7)\n",
        "    all_h = np.concatenate([np.abs(w_h).flatten(), np.abs(b_h).flatten()])\n",
        "    max_h = np.percentile(all_h, 99.9)\n",
        "    if max_h == 0:\n",
        "        max_h = 1.0\n",
        "    scale_h = 7.0 / max_h\n",
        "\n",
        "    w_h_int = np.clip(np.round(w_h * scale_h), -7, 7).astype(int)\n",
        "    b_h_int = np.clip(np.round(b_h * scale_h), -7, 7).astype(int)\n",
        "\n",
        "    print(f\"Hidden scale: {scale_h:.4f} (target ±7)\")\n",
        "\n",
        "    # Output layer scaling (target ±127)\n",
        "    all_o = np.concatenate([np.abs(w_o).flatten(), np.abs(b_o).flatten()])\n",
        "    max_o = np.percentile(all_o, 99.9)\n",
        "    if max_o == 0:\n",
        "        max_o = 1.0\n",
        "\n",
        "    scale_o = 127.0 / max_o\n",
        "\n",
        "    w_o_int = np.clip(np.round(w_o * scale_o), -127, 127).astype(int)\n",
        "    b_o_int = np.clip(np.round(b_o * scale_o), -127, 127).astype(int)\n",
        "\n",
        "    print(f\"Output scale: {scale_o:.4f} (target ±127)\")\n",
        "\n",
        "    # Forward pass simulation with integer weights\n",
        "    x_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "    hidden_raw = np.dot(x_flat, w_h_int) + b_h_int\n",
        "    hidden_out = np.maximum(0, hidden_raw)\n",
        "\n",
        "    final_raw = np.dot(hidden_out, w_o_int) + b_o_int\n",
        "\n",
        "    # Overflow check (16-bit accumulator)\n",
        "    max_acc = np.max(np.abs(final_raw))\n",
        "    print(f\"Max accumulator: {max_acc} (limit: 32767)\")\n",
        "\n",
        "    if max_acc > 32767:\n",
        "        print(\"Warning: overflow detected.\")\n",
        "    else:\n",
        "        print(\"Safe: 16-bit adder capacity used efficiently.\")\n",
        "\n",
        "    # Accuracy\n",
        "    pred = np.argmax(final_raw, axis=1)\n",
        "    acc = np.mean(pred == y_test) * 100\n",
        "\n",
        "    print(\"---------------------------------------------\")\n",
        "    print(f\"MINECRAFT ACCURACY: {acc:.2f}%\")\n",
        "    print(\"---------------------------------------------\")\n",
        "\n",
        "    print(\"Updating original model with integer-converted weights...\")\n",
        "\n",
        "    # Update model weights (store integer weights as float)\n",
        "    h_layer.set_weights([w_h_int.astype(float), b_h_int.astype(float)])\n",
        "    o_layer.set_weights([w_o_int.astype(float), b_o_int.astype(float)])\n",
        "\n",
        "    loss, keras_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Keras evaluate accuracy: {keras_acc * 100:.2f}%\")\n",
        "\n",
        "    return model, scale_o\n",
        "\n",
        "\n",
        "# RUN\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "# for i in range(3):\n",
        "#     print(f\"\\nRun #{i + 1}\")\n",
        "#     model = train_pro_model(x_train, y_train, x_test, y_test)\n",
        "#     simulate_optimized_accuracy(model, x_test, y_test)"
      ],
      "metadata": {
        "id": "fCcHOesVwisb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89c77da-0ac6-44f2-a473-6b02700772a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_v5 = model"
      ],
      "metadata": {
        "id": "4AK6cmxT6Bbm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_v5.save('model_v5.keras')"
      ],
      "metadata": {
        "id": "vVm9N5ya6PTX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v5 = tf.keras.models.load_model('model_v5.keras')"
      ],
      "metadata": {
        "id": "xpbDaL976Sv_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_items_for_signal(signal_strength):\n",
        "    \"\"\"Calculate number of items required to produce a given redstone signal (0–15).\"\"\"\n",
        "    if signal_strength <= 0:\n",
        "        return 0\n",
        "    if signal_strength == 1:\n",
        "        return 1\n",
        "    if signal_strength >= 15:\n",
        "        return 27 * 64\n",
        "\n",
        "    total_slots = 27\n",
        "    stack_size = 64\n",
        "    capacity = total_slots * stack_size\n",
        "\n",
        "    items_needed = math.ceil(((signal_strength - 1) * capacity) / 14)\n",
        "    return items_needed\n",
        "\n",
        "\n",
        "def generate_barrel_nbt(items_count):\n",
        "    \"\"\"Generate NBT data for a barrel filled with a given number of items.\"\"\"\n",
        "    if items_count == 0:\n",
        "        return \"\"\n",
        "\n",
        "    nbt_items = []\n",
        "    items_remaining = items_count\n",
        "    slot = 0\n",
        "\n",
        "    while items_remaining > 0 and slot < 27:\n",
        "        count = min(64, items_remaining)\n",
        "        nbt_items.append(\n",
        "            f'{{Slot:{slot}b, id:\"minecraft:cobblestone\", Count:{count}b}}'\n",
        "        )\n",
        "        items_remaining -= count\n",
        "        slot += 1\n",
        "\n",
        "    return \"{\" + f'Items:[{\",\".join(nbt_items)}]' + \"}\"\n",
        "\n",
        "\n",
        "def to_twos_complement(val):\n",
        "    \"\"\"\n",
        "    Convert integer (-8 to 7) to a 4-bit two's complement redstone signal (0–15).\n",
        "    \"\"\"\n",
        "    val = max(-8, min(7, val))\n",
        "\n",
        "    if val >= 0:\n",
        "        return val\n",
        "    else:\n",
        "        return 16 + val\n",
        "\n",
        "\n",
        "def export_schematics_twos_complement(model):\n",
        "    \"\"\"Export schematics with safe scaling for both weights and biases.\"\"\"\n",
        "    print(\"\\n--- GENERATE SCHEMATIC (SAFE SCALING: WEIGHT + BIAS) ---\")\n",
        "\n",
        "    layer = model.layers[1]\n",
        "    weights, biases = layer.get_weights()\n",
        "\n",
        "    max_weight = np.max(np.abs(weights))\n",
        "    max_bias = np.max(np.abs(biases))\n",
        "    absolute_max = max(max_weight, max_bias)\n",
        "\n",
        "    if absolute_max == 0:\n",
        "        absolute_max = 1.0\n",
        "\n",
        "    scale_factor = 7.0 / absolute_max\n",
        "\n",
        "    print(f\"Original Max Weight: {max_weight:.4f}\")\n",
        "    print(f\"Original Max Bias:   {max_bias:.4f}\")\n",
        "    print(f\"Scale Factor:        {scale_factor:.4f}\")\n",
        "\n",
        "    weights_int = np.round(weights * scale_factor).astype(int)\n",
        "    biases_int = np.round(biases * scale_factor).astype(int)\n",
        "\n",
        "    print(f\"New Weight Range: {weights_int.min()} to {weights_int.max()}\")\n",
        "    print(f\"New Bias Range:   {biases_int.min()} to {biases_int.max()}\")\n",
        "\n",
        "    for neuron_idx in range(10):\n",
        "        schem = mcschematic.MCSchematic()\n",
        "\n",
        "        w_neuron = weights_int[:, neuron_idx]\n",
        "        w_grid = w_neuron.reshape(28, 28)\n",
        "\n",
        "        bias_val = biases_int[neuron_idx]\n",
        "        bias_signal = to_twos_complement(bias_val)\n",
        "\n",
        "        print(f\"\\n=== NEURON {neuron_idx} ===\")\n",
        "        print(f\"Bias Integer: {bias_val} | Bias Signal: {bias_signal}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        for row in range(28):\n",
        "            line_str = \"\"\n",
        "            for col in range(28):\n",
        "                weight_val = w_grid[row, col]\n",
        "\n",
        "                if weight_val == 0:\n",
        "                    line_str += \" . \"\n",
        "                else:\n",
        "                    line_str += f\"{weight_val:2d} \"\n",
        "\n",
        "                signal_strength = to_twos_complement(weight_val)\n",
        "                items_needed = get_items_for_signal(signal_strength)\n",
        "                nbt_data = generate_barrel_nbt(items_needed)\n",
        "\n",
        "                x_pos = col * 2\n",
        "                y_pos = (27 - row) * 2\n",
        "                z_pos = 0\n",
        "\n",
        "                schem.setBlock(\n",
        "                    (x_pos, y_pos, z_pos),\n",
        "                    f\"minecraft:barrel{nbt_data}\"\n",
        "                )\n",
        "\n",
        "            print(line_str)\n",
        "\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        filename = f\"neuron_{neuron_idx}_twos_comp\"\n",
        "        schem.save(\".\", filename, version=mcschematic.Version.JE_1_20_1)\n",
        "        print(f\">>> Saved file: {filename}.schem\")\n",
        "\n",
        "    print(\"\\nDone. Bias is now guaranteed to be within -7 to +7.\")"
      ],
      "metadata": {
        "id": "PaDGVKg1RKR1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_schematics_twos_complement(model_v5)"
      ],
      "metadata": {
        "id": "1xNbc7lO6Zi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e988f82-98ff-4646-9597-9884789b1560"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GENERATE SCHEMATIC (SAFE SCALING: WEIGHT + BIAS) ---\n",
            "Original Max Weight: 7.0000\n",
            "Original Max Bias:   7.0000\n",
            "Scale Factor:        1.0000\n",
            "New Weight Range: -7 to 5\n",
            "New Bias Range:   -1 to 7\n",
            "\n",
            "=== NEURON 0 ===\n",
            "Bias Integer: 1 | Bias Signal: 1\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  1  1  .  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  . -2  .  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  . -1  .  .  .  . -2 -1 -2  .  .  .  . -1  .  .  1  1  2  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  . -1 -1  . -1  .  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -2  .  .  .  .  .  .  .  2  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  2  1  .  . -1 -1 -2 -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  1  . -1 -2 -1 -1  .  .  .  .  .  2  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  1  1 -1 -1 -1  . -1  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  2  2  2  .  .  .  .  .  .  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  1  2  1  3  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  3  2  2  2  2  2  .  .  .  .  .  . -1 -1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  3  2  1  2  2  3  .  1  1  1  1  . -1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  1  2  2  2  2  1  .  .  1  .  . -1  . -1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  2  1  2  2  2  2  1  .  .  .  .  . -1  . -1  .  1  1  .  .  . \n",
            " .  .  .  .  .  .  .  1  1  .  2  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  .  .  1  1  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  .  1  1  .  .  .  .  .  .  .  .  .  2  2  .  .  .  . \n",
            " .  .  .  .  . -2  .  .  .  .  1  .  1  1  .  .  .  .  1  .  1  1  .  .  .  .  .  . \n",
            " .  .  .  .  .  . -3  .  .  .  .  .  .  1  .  .  1  .  .  2  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  . -2 -2  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  . -4 -4 -1 -2 -2 -1 -1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  . -1 -1  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_0_twos_comp.schem\n",
            "\n",
            "=== NEURON 1 ===\n",
            "Bias Integer: 5 | Bias Signal: 5\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  . -1 -1 -2  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  . -1 -1  .  . -2  . -1  .  .  .  .  .  1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  . -1 -1 -1  . -1  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  1  .  .  1  2  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  1  .  .  1  2  2  2  3  1  2  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  .  .  1  .  2  .  1  .  .  1  .  .  2  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  .  .  . -1  .  .  .  .  .  1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  1  .  2  .  .  .  1  2  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  1  1  2  2  1  2  2  2  .  .  .  .  .  . -1  .  .  . \n",
            " .  .  .  .  .  1  .  3  1  1  2  2  2  2  1  2  2  1  2  .  .  .  . -3 -1  .  .  . \n",
            " .  .  .  .  4  .  .  .  1  2  2  1  1  1  .  1  1  2  1  1  .  .  . -2  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  1  .  1  1  2  .  .  .  1  2  1  1  .  .  .  . -3  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  1  1  1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1 -1  . -1  .  .  1  2  .  .  .  .  .  .  . -2  .  . \n",
            " .  .  .  .  .  .  .  .  . -1 -1  . -2 -1  .  .  .  .  .  .  .  .  . -1 -2  .  .  . \n",
            " .  .  .  .  .  . -1 -1  . -1 -2 -1 -2 -2 -1  .  .  .  .  .  .  . -2  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -2 -1 -1 -2 -2 -3 -1 -1  .  .  .  .  .  . -1  . -1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -2 -2  . -1 -1  .  .  .  .  .  .  .  . -1  .  .  .  . \n",
            " .  .  .  .  .  . -3  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  2  .  1  2  .  1  .  .  1  .  .  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  2  1  .  3  1  2  1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_1_twos_comp.schem\n",
            "\n",
            "=== NEURON 2 ===\n",
            "Bias Integer: 6 | Bias Signal: 6\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  2  .  .  .  . -2 -1 -1 -1 -1 -1  . -1  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  1  .  .  .  . -1 -1 -3 -2 -2 -2 -3 -2 -1 -1 -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  1  .  .  .  .  . -1  . -2 -2 -1  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  2  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  1  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  2  .  .  1  1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  1  1  2  2  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  2  1  2  3  3  .  .  .  .  .  . -1 -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  2  .  2  2  1  .  . -1 -1  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  1  1  .  .  . -1  .  .  .  .  .  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  2  1  2  1  1  3  2  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  1  1  3  1  3  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  . -1  . -1  .  .  .  .  .  1  2  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  2  .  .  .  .  . -1 -1 -1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  1  .  .  .  .  .  .  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_2_twos_comp.schem\n",
            "\n",
            "=== NEURON 3 ===\n",
            "Bias Integer: 3 | Bias Signal: 3\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  1  1  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  3  1  1  .  1  .  1  .  .  .  . -2  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  .  .  1  1  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  .  2  1  1  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  2  1  .  .  .  .  .  1  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  . -1 -1 -1  .  .  1  1  1  1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -1  . -3 -4 -5 -4 -4 -2  .  1  1  .  1  .  .  . -1  .  .  .  . \n",
            " .  .  .  .  . -2 -1 -7 -7 -7 -5 -3 -1 -2 -1  .  .  .  .  .  . -1  .  .  .  .  .  . \n",
            " .  .  . -1 -7 -7 -7 -7 -3  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  . -2  .  .  .  .  .  1  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  1  3  1  1  1  .  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  4  1  .  1  1  1  1  1  .  .  .  .  .  .  .  .  .  .  1  .  .  . \n",
            " .  .  .  .  .  .  .  2  .  .  .  .  .  1  .  .  .  2  .  1  .  .  .  .  2  4  .  . \n",
            " .  .  .  .  3  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  1  1  1  .  .  .  .  . \n",
            " .  .  .  .  2  1  1  .  .  . -1  .  .  .  .  .  .  1  .  .  .  .  2  .  4  .  .  . \n",
            " .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  1  1  1  .  .  .  .  . \n",
            " .  .  .  .  1  1  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  1  .  .  .  .  .  . \n",
            " .  .  .  .  1  1  .  .  .  .  .  .  .  .  .  .  .  .  1  1  .  2  1  .  .  .  .  . \n",
            " .  .  .  .  1  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  1  1  1  .  .  .  .  . \n",
            " .  .  .  .  .  1  .  1  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_3_twos_comp.schem\n",
            "\n",
            "=== NEURON 4 ===\n",
            "Bias Integer: -1 | Bias Signal: 15\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -2 -1  . -1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  .  .  .  .  1  2  1  1  .  1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  2  2  2  1  2  1  2  2  3  2  2  1  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  2  .  2  2  2  1  4  1  2  1  1  1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  1  .  .  2  2  1  2  3  2  3  1  1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  1  4  2  2  3  3  2  2  1  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  . -1  . -1 -2 -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  . -1 -2 -3 -4 -5 -5 -1  .  .  .  .  .  .  . -1  .  .  .  .  . \n",
            " .  .  .  .  .  . -2 -2 -3 -3 -2 -2 -3  .  .  .  .  .  .  .  . -2 -1  .  .  .  .  . \n",
            " .  .  .  .  . -7 -4 -2 -2 -2 -1 -2 -1  .  .  .  .  .  .  .  .  . -1  .  .  .  .  . \n",
            " .  .  .  . -1  .  .  . -1 -1  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  . -3  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -1  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  1  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  2  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  .  2  .  .  .  . -1 -1  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  1  2  1  3  1  1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_4_twos_comp.schem\n",
            "\n",
            "=== NEURON 5 ===\n",
            "Bias Integer: 0 | Bias Signal: 0\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  . -1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  . -1 -1  . -1  . -1  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  . -1 -1  . -1  .  . -2  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  . -1  .  .  . \n",
            " .  .  .  .  2  .  .  .  .  .  . -1  .  .  .  .  .  .  1  .  .  .  . -2 -2 -1  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  . -1  .  .  1  2  2  2  1  2  .  .  . -1 -4 -1  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  2  1  2  1  2  3  2  .  .  . -5  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  2  2  1  1  1  1  4  2  1  . -2  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1  .  .  .  3  2  2  2  1  2  2  2  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  3  3  2  1  1  1  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -1 -1  . -1  .  1  1  2  2  2  1  2  2  .  . -3  .  .  .  .  . \n",
            " .  .  .  .  .  . -3 -2  .  .  .  .  1  3  3  2  2  2  .  .  .  .  . -2  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  1  .  1  1  2  2  1  .  .  . -1 -2 -1  .  .  .  .  . \n",
            " .  .  .  .  . -1 -2  .  1  1  .  2  3  2  2  .  . -1 -1 -2 -2  .  .  .  .  .  .  . \n",
            " .  .  .  .  . -1 -1  .  .  .  .  1  .  2  .  . -1 -1  . -1  . -1 -1 -2  .  .  .  . \n",
            " .  .  .  .  . -1 -1 -1 -1  .  .  .  .  .  . -1 -1 -1  .  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  . -1  .  . -1 -1  . -1  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  . -1 -1 -1 -1  .  . -1  .  .  .  .  . -1 -1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1 -1  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  . -1  . -1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_5_twos_comp.schem\n",
            "\n",
            "=== NEURON 6 ===\n",
            "Bias Integer: 7 | Bias Signal: 7\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  . -1 -3 -2  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1 -1 -3  . -1 -1 -1 -1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  . -1 -2 -2 -1 -1  . -2  . -1 -1 -1  . -1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  . -1 -1  . -1 -1 -1  . -1 -1 -1  . -1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  . -1  .  .  .  .  .  . -1  .  .  .  .  .  .  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1 -1  .  .  .  .  .  1  1  1  1  1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  . -1 -1 -1  .  1  2  3  3  2  3  1  .  1  .  .  1  .  .  . \n",
            " .  .  .  .  .  .  . -1  . -1  .  .  .  1  2  2  1  1  1  2  .  1  .  2  .  3  .  . \n",
            " .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  2  1  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  2  1  . -1 -3 -2 -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  1  .  .  .  .  1  .  .  . -1 -2 -4 -7 -6 -4  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  2  .  .  .  .  1  .  .  .  .  .  . -3  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  . -2  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  .  .  .  .  .  . -4 -3 -3  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  .  2  1  .  . -2  . -3  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  1  1  .  . -2 -1 -1 -1  . -3 -3  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  .  1  . -1 -1 -2 -1  . -1 -1  .  .  .  .  .  . \n",
            " .  .  .  . -2 -1  .  .  .  .  .  .  .  .  . -1 -1  .  . -1 -2 -1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  . -1  . -1 -1 -1 -3  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -2  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  . -1 -1  . -1  . -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_6_twos_comp.schem\n",
            "\n",
            "=== NEURON 7 ===\n",
            "Bias Integer: 4 | Bias Signal: 4\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  2  1  2  2  1  2  .  1  1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  1  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1  .  .  .  1  .  . -1 -1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  2  .  . -1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  3  3  .  .  .  .  .  .  .  .  .  2  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  1  3  5  2  .  .  .  .  .  . -1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  3  4  4  4  1  .  .  .  . -2  .  .  .  .  .  . \n",
            " .  .  .  .  . -1  . -2 -1  .  .  .  2  3  3  2  1  .  .  . -1 -1 -3 -1  .  .  .  . \n",
            " .  .  .  .  . -1 -3 -2 -1 -1  .  .  3  4  5  .  .  . -1  . -1  . -1  .  .  .  .  . \n",
            " .  .  .  .  .  . -2 -2 -3  .  .  1  1  2  3  .  . -2  .  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  1  .  1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  1  2  2  .  .  .  .  1  1  2  2  1  2  2  1  1  .  .  .  . \n",
            " .  .  .  .  1  1  1  2  2  .  .  .  .  1  .  1  1  1  1  2  .  1  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  1  2  2  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  1  .  .  .  .  .  1  1  .  .  1  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_7_twos_comp.schem\n",
            "\n",
            "=== NEURON 8 ===\n",
            "Bias Integer: 5 | Bias Signal: 5\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  2  .  1  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  . -1 -1  . -1 -1 -2  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  . -1  .  . -1  .  .  .  .  .  . -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  . -1  .  .  .  .  .  2  .  .  .  . -1  . -1  . -2  .  .  .  . \n",
            " .  .  .  .  .  . -2 -3  . -1 -1  .  .  .  .  .  .  . -2  . -2 -1 -1 -3 -3  .  .  . \n",
            " .  .  .  .  . -1  .  .  .  .  .  .  .  .  1  .  . -1 -1 -1 -1 -2 -2 -3 -4  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1 -1  . -1 -1 -1  . -1 -5  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  . -1  .  .  .  .  .  .  .  . -4  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  1  1  1  1  .  .  1  .  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  1  1  2  1  1  1  .  .  1  1  .  1  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  1  1  1  1  1  1  .  1  .  1  1  .  .  .  1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  1  1  2  .  .  1  .  .  1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  .  1  1  .  .  1  1  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  . -1 -1  .  .  1  .  .  1  .  .  .  .  1  1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  . -2 -1  .  .  .  .  2  1  .  1  1  1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  . -1  . -1  .  .  .  .  .  1  1  1  1  1  1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  . -1  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -2  .  .  . -1  . -1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  . -1 -1 -2 -2 -2 -1 -1 -3 -1 -1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  . -2 -1 -3 -2 -1 -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_8_twos_comp.schem\n",
            "\n",
            "=== NEURON 9 ===\n",
            "Bias Integer: 0 | Bias Signal: 0\n",
            "----------------------------------------\n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  . -1 -1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  1  2  1  1  1  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  1  1  2  3  1  2  1  1  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  . -1  .  .  .  .  .  .  1  2  3  1  1  1  1  1  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  1  1  1  1  1  2  1  1  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  1  2  .  .  1  2  .  2  .  2  4  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  2  .  . -1  .  .  1  2  2  1  1  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  3  2  . -1  .  .  .  .  .  1  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  1  .  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  1  .  .  1 -1  . -2  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  . -2 -1 -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  .  .  . -1 -2 -2 -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  . -4 -3 -1 -1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  1  1  . -3 -2 -3  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  .  1  .  .  .  . -1 -1 -1 -1  .  .  .  1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  2  .  .  1  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  1  1  .  .  .  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  1  .  .  1  2  .  .  1  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  1  .  2  1  2  1  1  .  .  .  . -2 -1  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  1  1  1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            " .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n",
            "----------------------------------------\n",
            ">>> Saved file: neuron_9_twos_comp.schem\n",
            "\n",
            "Done. Bias is now guaranteed to be within -7 to +7.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_optimized_accuracy(model_v5, x_test, y_test)"
      ],
      "metadata": {
        "id": "I-MavS4V6zkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a15544d-435b-404d-d802-1e79d59e4350"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== OPTIMAL SIMULATION (Hidden ±7 | Output ±127) ===\n",
            "Hidden scale: 1.0000 (target ±7)\n",
            "Output scale: 1.0104 (target ±127)\n",
            "Max accumulator: 13948 (limit: 32767)\n",
            "Safe: 16-bit adder capacity used efficiently.\n",
            "---------------------------------------------\n",
            "MINECRAFT ACCURACY: 91.42%\n",
            "---------------------------------------------\n",
            "Updating original model with integer-converted weights...\n",
            "Keras evaluate accuracy: 91.42%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Sequential name=sequential_12, built=True>, np.float32(1.0104065))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def export_output_layer_debug(model):\n",
        "    print(\"\\n\\n=======================================================\")\n",
        "    print(\"           OUTPUT LAYER ANALYSIS (Hidden -> Lamps)     \")\n",
        "    print(\"=======================================================\")\n",
        "\n",
        "    # Get final (output) layer\n",
        "    out_layer = model.layers[2]\n",
        "    weights, biases = out_layer.get_weights()\n",
        "\n",
        "    # Safe scaling to range -7 to +7\n",
        "    max_weight = np.max(np.abs(weights))\n",
        "    max_bias = np.max(np.abs(biases))\n",
        "    absolute_max = max(max_weight, max_bias)\n",
        "\n",
        "    if absolute_max == 0:\n",
        "        absolute_max = 1.0\n",
        "\n",
        "    scale_factor = 7.0 / absolute_max\n",
        "\n",
        "    weights_int = np.round(weights * scale_factor).astype(int)\n",
        "    biases_int = np.round(biases * scale_factor).astype(int)\n",
        "\n",
        "    print(f\"Output Layer Scale Factor: {scale_factor:.4f}\")\n",
        "    print(f\"Max Value Used for Scaling: {absolute_max:.4f}\")\n",
        "\n",
        "    # Show biases\n",
        "    print(\"\\n--- OUTPUT BIASES ---\")\n",
        "    print(\"Format: [Lamp Index] : Bias Int -> 2's Complement Signal (0–15)\")\n",
        "    for i in range(10):\n",
        "        val = biases_int[i]\n",
        "        signal = to_twos_complement(val)\n",
        "        print(f\"Lamp {i} : Bias {val:>2} -> Signal {signal}\")\n",
        "\n",
        "    # Show weight matrix\n",
        "    print(\"\\n--- WEIGHT MATRIX (Hidden → Output) ---\")\n",
        "    print(\"Row = From Hidden Neuron #X\")\n",
        "    print(\"Col = To Output Lamp #Y\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    header = \"      \" + \" \".join([f\"L{i}\" for i in range(10)])\n",
        "    print(header)\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for h in range(10):\n",
        "        row_str = f\"H-{h} |\"\n",
        "        for o in range(10):\n",
        "            val = weights_int[h][o]\n",
        "            row_str += f\"{val:3d}\"\n",
        "        print(row_str)\n",
        "\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "ukB1LaUlRVhr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_output_layer_debug(model_v5)"
      ],
      "metadata": {
        "id": "w7h8MNbO6te2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cde15d-7450-4033-f746-8df8a63c4cdf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=======================================================\n",
            "           OUTPUT LAYER ANALYSIS (Hidden -> Lamps)     \n",
            "=======================================================\n",
            "Output Layer Scale Factor: 0.0551\n",
            "Max Value Used for Scaling: 127.0000\n",
            "\n",
            "--- OUTPUT BIASES ---\n",
            "Format: [Lamp Index] : Bias Int -> 2's Complement Signal (0–15)\n",
            "Lamp 0 : Bias  0 -> Signal 0\n",
            "Lamp 1 : Bias  0 -> Signal 0\n",
            "Lamp 2 : Bias  0 -> Signal 0\n",
            "Lamp 3 : Bias -1 -> Signal 15\n",
            "Lamp 4 : Bias  0 -> Signal 0\n",
            "Lamp 5 : Bias  0 -> Signal 0\n",
            "Lamp 6 : Bias  0 -> Signal 0\n",
            "Lamp 7 : Bias  0 -> Signal 0\n",
            "Lamp 8 : Bias -1 -> Signal 15\n",
            "Lamp 9 : Bias  0 -> Signal 0\n",
            "\n",
            "--- WEIGHT MATRIX (Hidden → Output) ---\n",
            "Row = From Hidden Neuron #X\n",
            "Col = To Output Lamp #Y\n",
            "------------------------------------------------------------\n",
            "      L0 L1 L2 L3 L4 L5 L6 L7 L8 L9\n",
            "------------------------------------------------------------\n",
            "H-0 |  1 -4  1 -3  1  0  1 -4  2 -2\n",
            "H-1 | -2 -3 -4  0  3  2 -3  1  0  3\n",
            "H-2 |  0 -4  0  1  0  0  0  4 -2 -3\n",
            "H-3 |  0  0  6  5 -2 -1 -2  3 -3 -6\n",
            "H-4 |  0 -1  3  1 -6  1 -5  3  0 -1\n",
            "H-5 | -1  0  0  0  1 -7 -2  2  1  2\n",
            "H-6 |  0  3 -4 -3  0  6 -1  1 -2  1\n",
            "H-7 | -3  3  0  1 -3  2  0 -4  1 -3\n",
            "H-8 |  0  0  0 -2  0 -1  5 -1 -4  2\n",
            "H-9 |  5 -1  0  1 -5  0  0 -1  0  1\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def export_full_model_params(model, filename=\"FULL_MODEL_REDSTONE.txt\"):\n",
        "    print(f\"--- EXPORTING FULL MODEL DATA TO {filename} ---\")\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(\"=== TECHNICAL DOCUMENT: REDSTONE NEURAL NETWORK ===\\n\")\n",
        "        f.write(\"Integer Range: -7 to +7\\n\")\n",
        "        f.write(\"Negative Method: 2's Complement or Subtractor\\n\")\n",
        "        f.write(\"==============================================\\n\\n\")\n",
        "\n",
        "        # Hidden Layer\n",
        "        h_layer = model.layers[1]\n",
        "        w_h, b_h = h_layer.get_weights()\n",
        "\n",
        "        # Safe scaling (weights and bias)\n",
        "        max_w = np.max(np.abs(w_h))\n",
        "        max_b = np.max(np.abs(b_h))\n",
        "        abs_max_h = max(max_w, max_b)\n",
        "        if abs_max_h == 0:\n",
        "            abs_max_h = 1.0\n",
        "\n",
        "        scale_h = 7.0 / abs_max_h\n",
        "\n",
        "        w_h_int = np.round(w_h * scale_h).astype(int)\n",
        "        b_h_int = np.round(b_h * scale_h).astype(int)\n",
        "\n",
        "        f.write(\"--- [LAYER 1] HIDDEN LAYER (784 Input -> 10 Neurons) ---\\n\")\n",
        "        f.write(f\"Scale Factor: {scale_h:.4f} (Max Value: {abs_max_h:.4f})\\n\\n\")\n",
        "\n",
        "        # Hidden Bias\n",
        "        f.write(\"HIDDEN LAYER BIASES:\\n\")\n",
        "        for i in range(10):\n",
        "            f.write(f\"Neuron {i}: {b_h_int[i]}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # Hidden Weights (visual 28x28 grid)\n",
        "        for n in range(10):\n",
        "            f.write(f\"--- Weights for Hidden Neuron {n} ---\\n\")\n",
        "            w_grid = w_h_int[:, n].reshape(28, 28)\n",
        "            for row in range(28):\n",
        "                line = \"\"\n",
        "                for col in range(28):\n",
        "                    val = w_grid[row, col]\n",
        "                    if val == 0:\n",
        "                        line += \" . \"\n",
        "                    else:\n",
        "                        line += f\"{val:2d} \"\n",
        "                f.write(line + \"\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        # Output Layer\n",
        "        o_layer = model.layers[2]\n",
        "        w_o, b_o = o_layer.get_weights()\n",
        "\n",
        "        # Safe scaling\n",
        "        max_w_o = np.max(np.abs(w_o))\n",
        "        max_b_o = np.max(np.abs(b_o))\n",
        "        abs_max_o = max(max_w_o, max_b_o)\n",
        "        if abs_max_o == 0:\n",
        "            abs_max_o = 1.0\n",
        "\n",
        "        scale_o = 7.0 / abs_max_o\n",
        "\n",
        "        w_o_int = np.round(w_o * scale_o).astype(int)\n",
        "        b_o_int = np.round(b_o * scale_o).astype(int)\n",
        "\n",
        "        f.write(\"\\n==============================================\\n\")\n",
        "        f.write(\"--- [LAYER 2] OUTPUT LAYER (10 Hidden -> 10 Lamps) ---\\n\")\n",
        "        f.write(f\"Scale Factor: {scale_o:.4f} (Max Value: {abs_max_o:.4f})\\n\\n\")\n",
        "\n",
        "        # Output biases\n",
        "        f.write(\"OUTPUT LAYER BIASES:\\n\")\n",
        "        for i in range(10):\n",
        "            f.write(f\"Lamp {i}: {b_o_int[i]}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # Output connection matrix\n",
        "        f.write(\"CONNECTION MATRIX (Row=Hidden, Column=Lamp):\\n\")\n",
        "        header = \"      \" + \" \".join([f\"L{i}\" for i in range(10)])\n",
        "        f.write(header + \"\\n\")\n",
        "        f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "        for h in range(10):\n",
        "            row_str = f\"H-{h} |\"\n",
        "            for o in range(10):\n",
        "                val = w_o_int[h][o]\n",
        "                row_str += f\"{val:3d}\"\n",
        "            f.write(row_str + \"\\n\")\n",
        "\n",
        "    print(\"Success! FULL_MODEL_REDSTONE.txt has been updated.\")\n",
        "\n",
        "\n",
        "def trace_redstone_logic(model, x_test, y_test, image_index=0):\n",
        "    print(f\"\\n\\n>>> TRACING REDSTONE LOGIC FOR IMAGE INDEX {image_index} <<<\")\n",
        "\n",
        "    # Input data\n",
        "    input_grid = x_test[image_index].reshape(28, 28)\n",
        "    img = input_grid.flatten()\n",
        "    true_label = y_test[image_index]\n",
        "\n",
        "    print(f\"True Label: {true_label}\")\n",
        "\n",
        "    # Hidden layer scaling\n",
        "    h_layer = model.layers[1]\n",
        "    w_h, b_h = h_layer.get_weights()\n",
        "\n",
        "    abs_max_h = max(np.max(np.abs(w_h)), np.max(np.abs(b_h)))\n",
        "    if abs_max_h == 0:\n",
        "        abs_max_h = 1.0\n",
        "    scale_h = 7.0 / abs_max_h\n",
        "\n",
        "    w_h_int = np.round(w_h * scale_h).astype(int)\n",
        "    b_h_int = np.round(b_h * scale_h).astype(int)\n",
        "\n",
        "    print(\"\\n[STEP 1] HIDDEN LAYER (ReLU Output)\")\n",
        "    hidden_outputs = []\n",
        "\n",
        "    for n in range(10):\n",
        "        raw_sum = np.dot(img, w_h_int[:, n])\n",
        "        total = raw_sum + b_h_int[n]\n",
        "        output = max(0, total)\n",
        "        hidden_outputs.append(output)\n",
        "\n",
        "    # Output layer\n",
        "    o_layer = model.layers[2]\n",
        "    w_o, b_o = o_layer.get_weights()\n",
        "\n",
        "    abs_max_o = max(np.max(np.abs(w_o)), np.max(np.abs(b_o)))\n",
        "    if abs_max_o == 0:\n",
        "        abs_max_o = 1.0\n",
        "    scale_o = 7.0 / abs_max_o\n",
        "\n",
        "    w_o_int = np.round(w_o * scale_o).astype(int)\n",
        "    b_o_int = np.round(b_o * scale_o).astype(int)\n",
        "\n",
        "    print(\"\\n[STEP 2] OUTPUT LAYER (Lamps)\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'Lamp':<8} | {'Bias':<5} | {'Total Signal':<12} | {'Bar'}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    final_scores = []\n",
        "    for digit in range(10):\n",
        "        weighted_sum = np.dot(hidden_outputs, w_o_int[:, digit])\n",
        "        final_total = weighted_sum + b_o_int[digit]\n",
        "        final_scores.append(final_total)\n",
        "\n",
        "        bar_len = int(max(0, final_total) / 5)\n",
        "        bar_char = \"█\" * bar_len\n",
        "        print(f\"Lamp {digit:<2} | {b_o_int[digit]:<5} | {final_total:<12} | {bar_char}\")\n",
        "\n",
        "    pred = np.argmax(final_scores)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Prediction: {pred} | True Answer: {true_label}\")\n",
        "    status = \"CORRECT\" if pred == true_label else \"WRONG\"\n",
        "    print(f\"Result: {status}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(input_grid, cmap='gray')\n",
        "    plt.title(f\"Input Digit: {true_label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    colors = ['gray'] * 10\n",
        "    colors[pred] = 'green'\n",
        "    if pred != true_label:\n",
        "        colors[true_label] = 'red'\n",
        "\n",
        "    bars = plt.bar(range(10), final_scores, color=colors)\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 1, int(yval),\n",
        "                 ha='center', va='bottom')\n",
        "\n",
        "    plt.xlabel(\"Output Lamp\")\n",
        "    plt.ylabel(\"Signal Strength\")\n",
        "    plt.title(f\"Output Signals — Predicted {pred}\")\n",
        "    plt.xticks(range(10))\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8jXqcjYxRdh4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_full_model_params(model_v5)\n",
        "trace_redstone_logic(model_v5, x_test, y_test, image_index=0)"
      ],
      "metadata": {
        "id": "3Wwg1jBF8JKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "outputId": "1b93816c-1a3e-4fc4-9aef-a5fe2286bcd3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- EXPORTING FULL MODEL DATA TO FULL_MODEL_REDSTONE.txt ---\n",
            "Success! FULL_MODEL_REDSTONE.txt has been updated.\n",
            "\n",
            "\n",
            ">>> TRACING REDSTONE LOGIC FOR IMAGE INDEX 0 <<<\n",
            "True Label: 7\n",
            "\n",
            "[STEP 1] HIDDEN LAYER (ReLU Output)\n",
            "\n",
            "[STEP 2] OUTPUT LAYER (Lamps)\n",
            "--------------------------------------------------\n",
            "Lamp     | Bias  | Total Signal | Bar\n",
            "--------------------------------------------------\n",
            "Lamp 0  | 0     | 47           | █████████\n",
            "Lamp 1  | 0     | -161         | \n",
            "Lamp 2  | 0     | 37           | ███████\n",
            "Lamp 3  | -1    | 106          | █████████████████████\n",
            "Lamp 4  | 0     | -300         | \n",
            "Lamp 5  | 0     | -50          | \n",
            "Lamp 6  | 0     | -368         | \n",
            "Lamp 7  | 0     | 229          | █████████████████████████████████████████████\n",
            "Lamp 8  | -1    | -27          | \n",
            "Lamp 9  | 0     | 45           | █████████\n",
            "--------------------------------------------------\n",
            "Prediction: 7 | True Answer: 7\n",
            "Result: CORRECT\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
